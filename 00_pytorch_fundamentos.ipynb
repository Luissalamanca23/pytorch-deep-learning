{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\"/></a> \n",
    "\n",
    "[Ver Código Fuente](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb) | [Ver Diapositivas](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/00_pytorch_and_deep_learning_fundamentals.pdf) | [Ver Video Tutorial](https://youtu.be/Z_ikDlimN6A?t=76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. Fundamentos de PyTorch\n",
    "\n",
    "## ¿Qué es PyTorch?\n",
    "\n",
    "[PyTorch](https://pytorch.org/) es un framework de código abierto para aprendizaje automático y aprendizaje profundo.\n",
    "\n",
    "## ¿Para qué se puede usar PyTorch?\n",
    "\n",
    "PyTorch te permite manipular y procesar datos y escribir algoritmos de aprendizaje automático usando código Python.\n",
    "\n",
    "## ¿Quién usa PyTorch?\n",
    "\n",
    "Muchas de las compañías tecnológicas más grandes del mundo como [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), Tesla y Microsoft, así como compañías de investigación en inteligencia artificial como [OpenAI usan PyTorch](https://openai.com/blog/openai-pytorch/) para impulsar la investigación y llevar el aprendizaje automático a sus productos.\n",
    "\n",
    "![pytorch siendo usado en la industria y la investigación](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png)\n",
    "\n",
    "Por ejemplo, Andrej Karpathy (jefe de IA en Tesla) ha dado varias charlas ([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904)) sobre cómo Tesla usa PyTorch para impulsar sus modelos de visión por computadora para conducción autónoma.\n",
    "\n",
    "PyTorch también se usa en otras industrias como la agricultura para [impulsar visión por computadora en tractores](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n",
    "\n",
    "## ¿Por qué usar PyTorch?\n",
    "\n",
    "A los investigadores de aprendizaje automático les encanta usar PyTorch. Y a partir de febrero de 2022, PyTorch es el [framework de aprendizaje profundo más usado en Papers With Code](https://paperswithcode.com/trends), un sitio web para rastrear papers de investigación en aprendizaje automático y los repositorios de código adjuntos.\n",
    "\n",
    "PyTorch también ayuda a cuidar muchas cosas como la aceleración por GPU (hacer que tu código funcione más rápido) detrás de escena.\n",
    "\n",
    "Así que puedes enfocarte en manipular datos y escribir algoritmos y PyTorch se asegurará de que funcione rápido.\n",
    "\n",
    "Y si compañías como Tesla y Meta (Facebook) lo usan para construir modelos que despliegan para impulsar cientos de aplicaciones, conducir miles de autos y entregar contenido a miles de millones de personas, claramente es capaz también en el frente de desarrollo.\n",
    "\n",
    "## Lo que vamos a cubrir en este módulo\n",
    "\n",
    "Este curso está dividido en diferentes secciones (notebooks).\n",
    "\n",
    "Cada notebook cubre ideas y conceptos importantes dentro de PyTorch.\n",
    "\n",
    "Los notebooks subsecuentes se basan en el conocimiento del anterior (la numeración comienza en 00, 01, 02 y va hasta donde sea que termine).\n",
    "\n",
    "Este notebook trata sobre el bloque de construcción básico del aprendizaje automático y el aprendizaje profundo, el tensor.\n",
    "\n",
    "Específicamente, vamos a cubrir:\n",
    "\n",
    "| **Tema** | **Contenidos** |\n",
    "| ----- | ----- |\n",
    "| **Introducción a tensores** | Los tensores son el bloque de construcción básico de todo el aprendizaje automático y aprendizaje profundo. |\n",
    "| **Creando tensores** | Los tensores pueden representar casi cualquier tipo de datos (imágenes, palabras, tablas de números). |\n",
    "| **Obteniendo información de tensores** | Si puedes poner información en un tensor, también querrás sacarla. |\n",
    "| **Manipulando tensores** | Los algoritmos de aprendizaje automático (como las redes neuronales) involucran manipular tensores de muchas maneras diferentes como sumar, multiplicar, combinar. |\n",
    "| **Tratando con formas de tensores** | Uno de los problemas más comunes en aprendizaje automático es lidiar con desajustes de forma (tratar de mezclar tensores de formas incorrectas con otros tensores). |\n",
    "| **Indexación en tensores** | Si has indexado en una lista de Python o array de NumPy, es muy similar con tensores, excepto que pueden tener muchas más dimensiones. |\n",
    "| **Mezclando tensores de PyTorch y NumPy** | PyTorch juega con tensores ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy le gustan los arrays ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)) a veces querrás mezclar estos. |\n",
    "| **Reproducibilidad** | El aprendizaje automático es muy experimental y dado que usa mucha *aleatoriedad* para funcionar, a veces querrás que esa *aleatoriedad* no sea tan aleatoria. |\n",
    "| **Ejecutando tensores en GPU** | Las GPUs (Unidades de Procesamiento Gráfico) hacen que tu código sea más rápido, PyTorch hace que sea fácil ejecutar tu código en GPUs. |\n",
    "\n",
    "## ¿Dónde puedes obtener ayuda?\n",
    "\n",
    "Todos los materiales para este curso [viven en GitHub](https://github.com/mrdbourke/pytorch-deep-learning).\n",
    "\n",
    "Y si tienes problemas, puedes hacer una pregunta en la [página de Discusiones](https://github.com/mrdbourke/pytorch-deep-learning/discussions) ahí también.\n",
    "\n",
    "También están los [foros de desarrolladores de PyTorch](https://discuss.pytorch.org/), un lugar muy útil para todo lo relacionado con PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando PyTorch\n",
    "\n",
    "> **Nota:** Antes de ejecutar cualquier código en este notebook, deberías haber pasado por los [pasos de configuración de PyTorch](https://pytorch.org/get-started/locally/).\n",
    ">\n",
    "> Sin embargo, **si estás ejecutando en Google Colab**, todo debería funcionar (Google Colab viene con PyTorch y otras librerías instaladas).\n",
    "\n",
    "Comencemos importando PyTorch y verificando la versión que estamos usando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0+cu124\n",
      "Uninstalling torch-2.6.0+cu124:\n",
      "  Successfully uninstalled torch-2.6.0+cu124\n",
      "Found existing installation: torchvision 0.21.0+cu124\n",
      "Uninstalling torchvision-0.21.0+cu124:\n",
      "  Successfully uninstalled torchvision-0.21.0+cu124\n",
      "Found existing installation: torchaudio 2.6.0+cu124\n",
      "Uninstalling torchaudio-2.6.0+cu124:\n",
      "  Successfully uninstalled torchaudio-2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu124\n",
      "Collecting torch==2.7.0.dev20250310+cu124\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu124/torch-2.7.0.dev20250310%2Bcu124-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.0.dev20250310+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (0.6.2)\n",
      "Collecting nvidia-nccl-cu12==2.25.1 (from torch==2.7.0.dev20250310+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu124/nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.conda/lib/python3.11/site-packages (from torch==2.7.0.dev20250310+cu124) (12.4.127)\n",
      "Collecting pytorch-triton==3.2.0+git4b3bb1f8 (from torch==2.7.0.dev20250310+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/pytorch_triton-3.2.0%2Bgit4b3bb1f8-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.7.0.dev20250310+cu124) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.conda/lib/python3.11/site-packages (from jinja2->torch==2.7.0.dev20250310+cu124) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/nightly/cu124/torch-2.7.0.dev20250310%2Bcu124-cp311-cp311-manylinux_2_28_x86_64.whl (866.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.3/866.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu124/nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.2.0%2Bgit4b3bb1f8-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.5/166.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytorch-triton, sympy, nvidia-nccl-cu12, torch\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [pytorch-triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.13.1[0m \u001b[32m0/4\u001b[0m [pytorch-triton]\n",
      "\u001b[2K    Uninstalling sympy-1.13.1:━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [pytorch-triton]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.1━\u001b[0m \u001b[32m0/4\u001b[0m [pytorch-triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [torch]32m3/4\u001b[0m [torch]-nccl-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-nccl-cu12-2.25.1 pytorch-triton-3.2.0+git4b3bb1f8 sympy-1.14.0 torch-2.7.0.dev20250310+cu124\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.7.0.dev20250310+cu124 --index-url https://download.pytorch.org/whl/nightly/cu124\n",
    "!pip install torchvision==0.22.0.dev20250310+cu124 --index-url https://download.pytorch.org/whl/nightly/cu124\n",
    "!pip install torchaudio==2.6.0.dev20250310+cu124 --index-url https://download.pytorch.org/whl/nightly/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (107 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.conda/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [matplotlib]6\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1+cu126'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maravilloso, parece que tenemos PyTorch 1.10.0+.\n",
    "\n",
    "Esto significa que si estás pasando por estos materiales, verás mayor compatibilidad con PyTorch 1.10.0+, sin embargo si tu número de versión es mucho más alto que eso, podrías notar algunas inconsistencias.\n",
    "\n",
    "Y si tienes algún problema, por favor publica en la [página de Discusiones de GitHub del curso](https://github.com/mrdbourke/pytorch-deep-learning/discussions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a tensores\n",
    "\n",
    "Ahora que tenemos PyTorch importado, es hora de aprender sobre tensores.\n",
    "\n",
    "Los tensores son el bloque de construcción fundamental del aprendizaje automático.\n",
    "\n",
    "Su trabajo es representar datos de manera numérica.\n",
    "\n",
    "Por ejemplo, podrías representar una imagen como un tensor con forma `[3, 224, 224]` lo que significaría `[canales_color, altura, ancho]`, como en que la imagen tiene `3` canales de color (rojo, verde, azul), una altura de `224` píxeles y un ancho de `224` píxeles.\n",
    "\n",
    "![ejemplo de ir de una imagen de entrada a una representación tensor de la imagen, la imagen se descompone en 3 canales de color así como números para representar la altura y el ancho](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
    "\n",
    "En jerga de tensores (el lenguaje usado para describir tensores), el tensor tendría tres dimensiones, una para `canales_color`, `altura` y `ancho`.\n",
    "\n",
    "Pero nos estamos adelantando.\n",
    "\n",
    "Aprendamos más sobre tensores codificándolos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando tensores\n",
    "\n",
    "PyTorch ama los tensores. Tanto que hay una página completa de documentación dedicada a la clase [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html).\n",
    "\n",
    "Tu primera tarea es [leer la documentación sobre `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) por 10 minutos. Pero puedes llegar a eso después.\n",
    "\n",
    "Codifiquemos.\n",
    "\n",
    "Lo primero que vamos a crear es un **escalar**.\n",
    "\n",
    "Un escalar es un número único y en jerga de tensores es un tensor de dimensión cero.\n",
    "\n",
    "> **Nota:** Esa es una tendencia para este curso. Nos enfocaremos en escribir código específico. Pero a menudo estableceré ejercicios que involucran leer y familiarizarse con la documentación de PyTorch. Porque después de todo, una vez que termines este curso, sin duda querrás aprender más. Y la documentación es un lugar donde te encontrarás bastante a menudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escalar\n",
    "escalar = torch.tensor(7)\n",
    "escalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Ves cómo lo de arriba imprimió `tensor(7)`?\n",
    "\n",
    "Eso significa que aunque `escalar` es un número único, es de tipo `torch.Tensor`.\n",
    "\n",
    "Podemos verificar las dimensiones de un tensor usando el atributo `ndim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué tal si quisiéramos recuperar el número del tensor?\n",
    "\n",
    "Como en, convertirlo de `torch.Tensor` a un entero de Python?\n",
    "\n",
    "Para hacerlo podemos usar el método `item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener el número de Python dentro de un tensor (solo funciona con tensores de un elemento)\n",
    "escalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, ahora veamos un **vector**.\n",
    "\n",
    "Un vector es un tensor de una dimensión pero puede contener muchos números.\n",
    "\n",
    "Como en, podrías tener un vector `[3, 2]` para describir `[habitaciones, baños]` en tu casa. O podrías tener `[3, 2, 2]` para describir `[habitaciones, baños, estacionamientos]` en tu casa.\n",
    "\n",
    "La tendencia importante aquí es que un vector es flexible en lo que puede representar (lo mismo con los tensores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maravilloso, `vector` ahora contiene dos 7s, mi número favorito.\n",
    "\n",
    "¿Cuántas dimensiones crees que tendrá?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar el número de dimensiones del vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, eso es extraño, `vector` contiene dos números pero solo tiene una dimensión.\n",
    "\n",
    "Te voy a contar un truco.\n",
    "\n",
    "Puedes saber el número de dimensiones que tiene un tensor en PyTorch por el número de corchetes en el exterior (`[`) y solo necesitas contar un lado.\n",
    "\n",
    "¿Cuántos corchetes tiene `vector`?\n",
    "\n",
    "Otro concepto importante para los tensores es su atributo `shape`. La forma te dice cómo están organizados los elementos dentro de ellos.\n",
    "\n",
    "Revisemos la forma de `vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar forma del vector\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo de arriba devuelve `torch.Size([2])` lo que significa que nuestro vector tiene una forma de `[2]`. Esto es debido a los dos elementos que colocamos dentro de los corchetes (`[7, 7]`).\n",
    "\n",
    "Ahora veamos una **matriz**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz\n",
    "MATRIZ = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "MATRIZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Wow! ¡Más números! Las matrices son tan flexibles como los vectores, excepto que tienen una dimensión extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar número de dimensiones\n",
    "MATRIZ.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MATRIZ` tiene dos dimensiones (¿contaste el número de corchetes en el exterior de un lado?).\n",
    "\n",
    "¿Qué `forma` crees que tendrá?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIZ.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la salida `torch.Size([2, 2])` porque `MATRIZ` tiene dos elementos de profundidad y dos elementos de ancho.\n",
    "\n",
    "¿Qué tal si creamos un **tensor**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Woah! Qué tensor tan bonito.\n",
    "\n",
    "Quiero enfatizar que los tensores pueden representar casi cualquier cosa.\n",
    "\n",
    "El que acabamos de crear podría ser los números de ventas para una tienda de carne y mantequilla de almendras (dos de mis comidas favoritas).\n",
    "\n",
    "![un tensor simple en google sheets mostrando día de la semana, ventas de carne y ventas de mantequilla de almendras](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n",
    "\n",
    "¿Cuántas dimensiones crees que tiene? (pista: usa el truco de contar corchetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar número de dimensiones para TENSOR\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y qué tal su forma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar forma de TENSOR\n",
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, da como salida `torch.Size([1, 3, 3])`.\n",
    "\n",
    "Las dimensiones van de exterior a interior.\n",
    "\n",
    "Eso significa que hay 1 dimensión de 3 por 3.\n",
    "\n",
    "![ejemplo de diferentes dimensiones de tensor](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
    "\n",
    "> **Nota:** Podrías haber notado que uso letras minúsculas para `escalar` y `vector` y letras mayúsculas para `MATRIZ` y `TENSOR`. Esto fue a propósito. En la práctica, a menudo verás escalares y vectores denotados como letras minúsculas como `y` o `a`. Y matrices y tensores denotados como letras mayúsculas como `X` o `W`.\n",
    ">\n",
    "> También podrías notar los nombres matriz y tensor usados intercambiablemente. Esto es común. Dado que en PyTorch a menudo tratas con `torch.Tensor`s (de ahí el nombre tensor), sin embargo, la forma y dimensiones de lo que esté adentro dictará lo que realmente es.\n",
    "\n",
    "Resumamos.\n",
    "\n",
    "| Nombre | ¿Qué es? | Número de dimensiones | Minúscula o mayúscula (usualmente/ejemplo) |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| **escalar** | un número único | 0 | Minúscula (`a`) |\n",
    "| **vector** | un número con dirección (ej. velocidad del viento con dirección) pero también puede tener muchos otros números | 1 | Minúscula (`y`) |\n",
    "| **matriz** | un array 2-dimensional de números | 2 | Mayúscula (`Q`) |\n",
    "| **tensor** | un array n-dimensional de números | puede ser cualquier número, un tensor 0-dimensional es un escalar, un tensor 1-dimensional es un vector | Mayúscula (`X`) |\n",
    "\n",
    "![escalar vector matriz tensor y cómo se ven](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensores aleatorios\n",
    "\n",
    "Hemos establecido que los tensores representan alguna forma de datos.\n",
    "\n",
    "Y los modelos de aprendizaje automático como las redes neuronales manipulan y buscan patrones dentro de tensores.\n",
    "\n",
    "Pero cuando construyes modelos de aprendizaje automático con PyTorch, es raro que crees tensores a mano (como lo que hemos estado haciendo).\n",
    "\n",
    "En su lugar, un modelo de aprendizaje automático a menudo comienza con grandes tensores aleatorios de números y ajusta estos números aleatorios a medida que trabaja con datos para representarlos mejor.\n",
    "\n",
    "En esencia:\n",
    "\n",
    "`Comenzar con números aleatorios -> mirar datos -> actualizar números aleatorios -> mirar datos -> actualizar números aleatorios...`\n",
    "\n",
    "Como científico de datos, puedes definir cómo el modelo de aprendizaje automático comienza (inicialización), mira datos (representación) y actualiza (optimización) sus números aleatorios.\n",
    "\n",
    "Nos pondremos manos a la obra con estos pasos más adelante.\n",
    "\n",
    "Por ahora, veamos cómo crear un tensor de números aleatorios.\n",
    "\n",
    "Podemos hacerlo usando [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) y pasando el parámetro `size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0428, 0.4498, 0.9708, 0.0040],\n",
       "         [0.9562, 0.0681, 0.7080, 0.3191],\n",
       "         [0.8666, 0.7719, 0.7032, 0.9902]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor aleatorio de tamaño (3, 4)\n",
    "tensor_aleatorio = torch.rand(size=(3, 4))\n",
    "tensor_aleatorio, tensor_aleatorio.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La flexibilidad de `torch.rand()` es que podemos ajustar el `size` para que sea lo que queramos.\n",
    "\n",
    "Por ejemplo, digamos que querías un tensor aleatorio en la forma común de imagen de `[224, 224, 3]` (`[altura, ancho, canales_color]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor aleatorio de tamaño (224, 224, 3)\n",
    "tensor_tamaño_imagen_aleatorio = torch.rand(size=(224, 224, 3))\n",
    "tensor_tamaño_imagen_aleatorio.shape, tensor_tamaño_imagen_aleatorio.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ceros y unos\n",
    "\n",
    "A veces solo querrás llenar tensores con ceros o unos.\n",
    "\n",
    "Esto sucede mucho con enmascaramiento (como enmascarar algunos de los valores en un tensor con ceros para hacer saber a un modelo que no los aprenda).\n",
    "\n",
    "Creemos un tensor lleno de ceros con [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)\n",
    "\n",
    "De nuevo, el parámetro `size` entra en juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor de todos ceros\n",
    "ceros = torch.zeros(size=(3, 4))\n",
    "ceros, ceros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer lo mismo para crear un tensor de todos unos excepto usando [`torch.ones()`](https://pytorch.org/docs/stable/generated/torch.ones.html) en su lugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor de todos unos\n",
    "unos = torch.ones(size=(3, 4))\n",
    "unos, unos.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando un rango y tensores como\n",
    "\n",
    "A veces podrías querer un rango de números, como 1 a 10 o 0 a 100.\n",
    "\n",
    "Puedes usar `torch.arange(start, end, step)` para hacerlo.\n",
    "\n",
    "Donde:\n",
    "* `start` = inicio del rango (ej. 0)\n",
    "* `end` = final del rango (ej. 10)\n",
    "* `step` = cuántos pasos entre cada valor (ej. 1)\n",
    "\n",
    "> **Nota:** En Python, puedes usar `range()` para crear un rango. Sin embargo en PyTorch, `torch.range()` está obsoleto y puede mostrar un error en el futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12197/3072048001.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  cero_a_diez_obsoleto = torch.range(0, 10) # Nota: esto puede devolver un error en el futuro\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usar torch.arange(), torch.range() está obsoleto\n",
    "cero_a_diez_obsoleto = torch.range(0, 10) # Nota: esto puede devolver un error en el futuro\n",
    "\n",
    "# Crear un rango de valores de 0 a 10\n",
    "cero_a_diez = torch.arange(start=0, end=10, step=1)\n",
    "cero_a_diez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A veces podrías querer un tensor de cierto tipo con la misma forma que otro tensor.\n",
    "\n",
    "Por ejemplo, un tensor de todos ceros con la misma forma que un tensor previo.\n",
    "\n",
    "Para hacerlo puedes usar [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) o [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) que devuelven un tensor lleno con ceros o unos en la misma forma que el `input` respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# También se puede crear un tensor de ceros similar a otro tensor\n",
    "diez_ceros = torch.zeros_like(input=cero_a_diez) # tendrá la misma forma\n",
    "diez_ceros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de datos de tensor\n",
    "\n",
    "Hay muchos [tipos de datos de tensor diferentes disponibles en PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "\n",
    "Algunos son específicos para CPU y algunos son mejores para GPU.\n",
    "\n",
    "Conocer cuál usar puede tomar algún tiempo.\n",
    "\n",
    "Generalmente si ves `torch.cuda` en cualquier lugar, el tensor se está usando para GPU (ya que las GPUs Nvidia usan un toolkit de computación llamado CUDA).\n",
    "\n",
    "El tipo más común (y generalmente el predeterminado) es `torch.float32` o `torch.float`.\n",
    "\n",
    "Esto se refiere como \"punto flotante de 32-bit\".\n",
    "\n",
    "Pero también está el punto flotante de 16-bit (`torch.float16` o `torch.half`) y punto flotante de 64-bit (`torch.float64` o `torch.double`).\n",
    "\n",
    "Y para confundir las cosas aún más también hay enteros de 8-bit, 16-bit, 32-bit y 64-bit.\n",
    "\n",
    "¡Y más!\n",
    "\n",
    "> **Nota:** Un entero es un número redondo plano como `7` mientras que un flotante tiene un decimal `7.0`.\n",
    "\n",
    "La razón para todos estos tiene que ver con **precisión en computación**.\n",
    "\n",
    "Precisión es la cantidad de detalle usado para describir un número.\n",
    "\n",
    "El valor de precisión más alto (8, 16, 32), más detalle y por lo tanto más datos usados para expresar un número.\n",
    "\n",
    "Esto importa en aprendizaje profundo y computación numérica porque estás haciendo tantas operaciones, entre más detalle tengas que calcular, más cómputo tienes que usar.\n",
    "\n",
    "Así que los tipos de datos de menor precisión son generalmente más rápidos de computar pero sacrifican algo de rendimiento en métricas de evaluación como precisión (más rápido de computar pero menos preciso).\n",
    "\n",
    "> **Recursos:**\n",
    "  * Ve la [documentación de PyTorch para una lista de todos los tipos de datos de tensor disponibles](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "  * Lee la [página de Wikipedia para un resumen de qué es precisión en computación](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
    "\n",
    "Veamos cómo crear algunos tensores con tipos de datos específicos. Podemos hacerlo usando el parámetro `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo de dato predeterminado para tensores es float32\n",
    "tensor_float_32 = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # predeterminado es None, que es torch.float32 o cualquier tipo de dato que se pase\n",
    "                               device=None, # predeterminado es None, que usa el tipo de tensor predeterminado\n",
    "                               requires_grad=False) # si es True, las operaciones realizadas en el tensor se registran\n",
    "\n",
    "tensor_float_32.shape, tensor_float_32.dtype, tensor_float_32.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparte de problemas de forma (las formas de tensor no coinciden), dos de los otros problemas más comunes que encontrarás en PyTorch son problemas de tipo de dato y dispositivo.\n",
    "\n",
    "Por ejemplo, uno de los tensores es `torch.float32` y el otro es `torch.float16` (PyTorch a menudo le gusta que los tensores estén en el mismo formato).\n",
    "\n",
    "O uno de tus tensores está en la CPU y el otro está en la GPU (a PyTorch le gusta que los cálculos entre tensores estén en el mismo dispositivo).\n",
    "\n",
    "Veremos más de esta charla de dispositivos más adelante.\n",
    "\n",
    "Por ahora creemos un tensor con `dtype=torch.float16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float_16 = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half también funcionaría\n",
    "\n",
    "tensor_float_16.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo información de tensores\n",
    "\n",
    "Una vez que hayas creado tensores (o alguien más o un módulo de PyTorch los haya creado para ti), podrías querer obtener información de ellos.\n",
    "\n",
    "Hemos visto estos antes pero tres de los atributos más comunes que querrás averiguar sobre tensores son:\n",
    "* `shape` - ¿qué forma tiene el tensor? (algunas operaciones requieren reglas de forma específicas)\n",
    "* `dtype` - ¿en qué tipo de dato están almacenados los elementos dentro del tensor?\n",
    "* `device` - ¿en qué dispositivo está almacenado el tensor? (usualmente GPU o CPU)\n",
    "\n",
    "Creemos un tensor aleatorio y averigüemos detalles sobre él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3699, 0.8327, 0.5855, 0.6994],\n",
      "        [0.9078, 0.8637, 0.0423, 0.0190],\n",
      "        [0.5496, 0.1149, 0.1026, 0.3939]])\n",
      "Forma del tensor: torch.Size([3, 4])\n",
      "Tipo de dato del tensor: torch.float32\n",
      "Dispositivo en el que está almacenado el tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "# Crear un tensor\n",
    "algun_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Averiguar detalles sobre él\n",
    "print(algun_tensor)\n",
    "print(f\"Forma del tensor: {algun_tensor.shape}\")\n",
    "print(f\"Tipo de dato del tensor: {algun_tensor.dtype}\")\n",
    "print(f\"Dispositivo en el que está almacenado el tensor: {algun_tensor.device}\") # predeterminado será CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota:** Cuando te encuentres con problemas en PyTorch, muy a menudo es uno que tiene que ver con uno de los tres atributos de arriba. Así que cuando aparezcan los mensajes de error, cántate una pequeña canción llamada \"qué, qué, dónde\":\n",
    "  * \"*¿qué forma tienen mis tensores? ¿qué tipo de dato son y dónde están almacenados? qué forma, qué tipo de dato, dónde dónde dónde*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulando tensores (operaciones de tensor)\n",
    "\n",
    "En aprendizaje profundo, los datos (imágenes, texto, video, audio, estructuras de proteínas, etc) se representan como tensores.\n",
    "\n",
    "Un modelo aprende investigando esos tensores y realizando una serie de operaciones (podrían ser 1,000,000s+) en tensores para crear una representación de los patrones en los datos de entrada.\n",
    "\n",
    "Estas operaciones son a menudo una danza maravillosa entre:\n",
    "* Suma\n",
    "* Resta\n",
    "* Multiplicación (elemento por elemento)\n",
    "* División\n",
    "* Multiplicación de matrices\n",
    "\n",
    "Y eso es todo. Seguro que hay unas pocas más aquí y allá pero estos son los bloques de construcción básicos de las redes neuronales.\n",
    "\n",
    "Apilando estos bloques de construcción de la manera correcta, puedes crear las redes neuronales más sofisticadas (¡igual que lego!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones básicas\n",
    "\n",
    "Comencemos con algunas de las operaciones fundamentales, suma (`+`), resta (`-`), multiplicación (`*`).\n",
    "\n",
    "Funcionan justo como piensas que funcionarían."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor de valores y agregar un número a él\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicar por 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota cómo los valores del tensor arriba no terminaron siendo `tensor([110, 120, 130])`, esto es porque los valores dentro del tensor no cambian a menos que sean reasignados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Los tensores no cambian a menos que sean reasignados\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restemos un número y esta vez reasignaremos la variable `tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restar y reasignar\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sumar y reasignar\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch también tiene un montón de funciones incorporadas como [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (abreviatura de multiplicación) y [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) para realizar operaciones básicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# También se pueden usar funciones de torch\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El tensor original sigue sin cambiar\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, es más común usar los símbolos de operador como `*` en lugar de `torch.mul()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Igual a: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Multiplicación elemento por elemento (cada elemento multiplica su equivalente, índice 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Igual a:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicación de matrices (es todo lo que necesitas)\n",
    "\n",
    "Una de las operaciones más comunes en algoritmos de aprendizaje automático y aprendizaje profundo (como redes neuronales) es [multiplicación de matrices](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "PyTorch implementa funcionalidad de multiplicación de matrices en el método [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Las dos reglas principales para multiplicación de matrices que recordar son:\n",
    "\n",
    "1. Las **dimensiones internas** deben coincidir:\n",
    "  * `(3, 2) @ (3, 2)` no funcionará\n",
    "  * `(2, 3) @ (3, 2)` funcionará\n",
    "  * `(3, 2) @ (2, 3)` funcionará\n",
    "2. La matriz resultante tiene la forma de las **dimensiones externas**:\n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    "> **Nota:** \"`@`\" en Python es el símbolo para multiplicación de matrices.\n",
    "\n",
    "> **Recurso:** Puedes ver todas las reglas para multiplicación de matrices usando `torch.matmul()` [en la documentación de PyTorch](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Creemos un tensor y realicemos multiplicación elemento por elemento y multiplicación de matrices en él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia entre multiplicación elemento por elemento y multiplicación de matrices es la suma de valores.\n",
    "\n",
    "Para nuestra variable `tensor` con valores `[1, 2, 3]`:\n",
    "\n",
    "| Operación | Cálculo | Código |\n",
    "| ----- | ----- | ----- |\n",
    "| **Multiplicación elemento por elemento** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
    "| **Multiplicación de matrices** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación de matrices elemento por elemento\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación de matrices\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# También se puede usar el símbolo \"@\" para multiplicación de matrices, aunque no se recomienda\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes hacer multiplicación de matrices a mano pero no se recomienda.\n",
    "\n",
    "El método incorporado `torch.matmul()` es más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 ms, sys: 208 μs, total: 1.34 ms\n",
      "Wall time: 1.84 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Multiplicación de matrices a mano\n",
    "# (evita hacer operaciones con bucles for a toda costa, son computacionalmente costosos)\n",
    "valor = 0\n",
    "for i in range(len(tensor)):\n",
    "  valor += tensor[i] * tensor[i]\n",
    "valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 495 μs, total: 495 μs\n",
      "Wall time: 430 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uno de los errores más comunes en aprendizaje profundo (errores de forma)\n",
    "\n",
    "Porque mucho del aprendizaje profundo es multiplicar y realizar operaciones en matrices y las matrices tienen una regla estricta sobre qué formas y tamaños se pueden combinar, uno de los errores más comunes que encontrarás en aprendizaje profundo es desajustes de forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m tensor_A = torch.tensor([[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m],\n\u001b[32m      3\u001b[39m                          [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m],\n\u001b[32m      4\u001b[39m                          [\u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m]], dtype=torch.float32)\n\u001b[32m      6\u001b[39m tensor_B = torch.tensor([[\u001b[32m7\u001b[39m, \u001b[32m10\u001b[39m],\n\u001b[32m      7\u001b[39m                          [\u001b[32m8\u001b[39m, \u001b[32m11\u001b[39m], \n\u001b[32m      8\u001b[39m                          [\u001b[32m9\u001b[39m, \u001b[32m12\u001b[39m]], dtype=torch.float32)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (esto dará error)\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Las formas necesitan estar de la manera correcta\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (esto dará error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer que la multiplicación de matrices funcione entre `tensor_A` y `tensor_B` haciendo que sus dimensiones internas coincidan.\n",
    "\n",
    "Una de las maneras de hacer esto es con una **transposición** (intercambiar las dimensiones de un tensor dado).\n",
    "\n",
    "Puedes realizar transposiciones en PyTorch usando:\n",
    "* `torch.transpose(input, dim0, dim1)` - donde `input` es el tensor deseado para transponer y `dim0` y `dim1` son las dimensiones a intercambiar.\n",
    "* `tensor.T` - donde `tensor` es el tensor deseado para transponer.\n",
    "\n",
    "Probemos lo último."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# Ver tensor_A y tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# Ver tensor_A y tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formas originales: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "Nuevas formas: tensor_A = torch.Size([3, 2]) (igual que arriba), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplicando: torch.Size([3, 2]) * torch.Size([2, 3]) <- las dimensiones internas coinciden\n",
      "\n",
      "Salida:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Forma de la salida: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# La operación funciona cuando tensor_B está transpuesto\n",
    "print(f\"Formas originales: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"Nuevas formas: tensor_A = {tensor_A.shape} (igual que arriba), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplicando: {tensor_A.shape} * {tensor_B.T.shape} <- las dimensiones internas coinciden\\n\")\n",
    "print(\"Salida:\\n\")\n",
    "salida = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(salida) \n",
    "print(f\"\\nForma de la salida: {salida.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes usar [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) que es una abreviatura de `torch.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm es un atajo para matmul\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin la transposición, las reglas de multiplicación de matrices no se cumplen y obtenemos un error como el de arriba.\n",
    "\n",
    "¿Qué tal un visual?\n",
    "\n",
    "![demostración visual de multiplicación de matrices](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
    "\n",
    "Puedes crear tus propios visuales de multiplicación de matrices como este en http://matrixmultiplication.xyz/.\n",
    "\n",
    "> **Nota:** Una multiplicación de matrices como esta también se refiere como el [**producto punto**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) de dos matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales están llenas de multiplicaciones de matrices y productos punto.\n",
    "\n",
    "El módulo [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) (lo veremos en acción más adelante), también conocido como capa feed-forward o capa completamente conectada, implementa una multiplicación de matrices entre una entrada `x` y una matriz de pesos `A`.\n",
    "\n",
    "$$\n",
    "y = x\\cdot{A^T} + b\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "* `x` es la entrada a la capa (el aprendizaje profundo es una pila de capas como `torch.nn.Linear()` y otras una encima de la otra).\n",
    "* `A` es la matriz de pesos creada por la capa, esto comienza como números aleatorios que se ajustan a medida que una red neuronal aprende a representar mejor los patrones en los datos (nota la \"`T`\", eso es porque la matriz de pesos se transpone).\n",
    "  * **Nota:** También podrías ver a menudo `W` u otra letra como `X` usada para mostrar la matriz de pesos.\n",
    "* `b` es el término de sesgo usado para desplazar ligeramente los pesos y entradas.\n",
    "* `y` es la salida (una manipulación de la entrada con la esperanza de descubrir patrones en ella).\n",
    "\n",
    "Esta es una función lineal (podrías haber visto algo como $y = mx+b$ en la preparatoria o en otro lugar), y se puede usar para dibujar una línea recta!\n",
    "\n",
    "Juguemos con una capa lineal.\n",
    "\n",
    "Trata de cambiar los valores de `in_features` y `out_features` abajo y ve qué pasa.\n",
    "\n",
    "¿Notas algo que tenga que ver con las formas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de entrada: torch.Size([3, 2])\n",
      "\n",
      "Salida:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Forma de salida: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Como la capa lineal comienza con una matriz de pesos aleatoria, hagámosla reproducible (más sobre esto después)\n",
    "torch.manual_seed(42)\n",
    "# Esto usa multiplicación de matrices\n",
    "lineal = torch.nn.Linear(in_features=2, # in_features = coincide con la dimensión interna de la entrada\n",
    "                         out_features=6) # out_features = describe el valor externo\n",
    "x = tensor_A\n",
    "salida = lineal(x)\n",
    "print(f\"Forma de entrada: {x.shape}\\n\")\n",
    "print(f\"Salida:\\n{salida}\\n\\nForma de salida: {salida.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pregunta:** ¿Qué pasa si cambias `in_features` de 2 a 3 arriba? ¿Da error? ¿Cómo podrías cambiar la forma de la entrada (`x`) para acomodarse al error? Pista: ¿qué tuvimos que hacer a `tensor_B` arriba?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nunca lo has hecho antes, la multiplicación de matrices puede ser un tema confuso al principio.\n",
    "\n",
    "Pero después de que hayas jugado con ella unas cuantas veces e incluso abierto algunas redes neuronales, notarás que está en todas partes.\n",
    "\n",
    "Recuerda, la multiplicación de matrices es todo lo que necesitas.\n",
    "\n",
    "![la multiplicación de matrices es todo lo que necesitas](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)\n",
    "\n",
    "*Cuando empieces a profundizar en las capas de redes neuronales y construir las tuyas propias, encontrarás multiplicaciones de matrices en todas partes. **Fuente:** https://marksaroufim.substack.com/p/working-class-deep-learner*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando el min, max, media, suma, etc (agregación)\n",
    "\n",
    "Ahora que hemos visto algunas maneras de manipular tensores, repasemos algunas maneras de agregarlos (ir de más valores a menos valores).\n",
    "\n",
    "Primero crearemos un tensor y luego encontraremos el máximo, mínimo, media y suma de él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realicemos algo de agregación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mínimo: {x.min()}\")\n",
    "print(f\"Máximo: {x.max()}\")\n",
    "# print(f\"Media: {x.mean()}\") # esto dará error\n",
    "print(f\"Media: {x.type(torch.float32).mean()}\") # no funcionará sin tipo de dato float\n",
    "print(f\"Suma: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota:** Podrías encontrar que algunos métodos como `torch.mean()` requieren que los tensores estén en `torch.float32` (el más común) u otro tipo de dato específico, de otra manera la operación fallará.\n",
    "\n",
    "También puedes hacer lo mismo que arriba con métodos `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min/max posicional\n",
    "\n",
    "También puedes encontrar el índice de un tensor donde ocurre el máximo o mínimo con [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) y [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectivamente.\n",
    "\n",
    "Esto es útil en caso de que solo quieras la posición donde está el valor más alto (o más bajo) y no el valor real en sí (veremos esto en una sección posterior cuando usemos la [función de activación softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Devuelve índice de valores max y min\n",
    "print(f\"Índice donde ocurre el valor máximo: {tensor.argmax()}\")\n",
    "print(f\"Índice donde ocurre el valor mínimo: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar tipo de dato de tensor\n",
    "\n",
    "Como se mencionó, un problema común con operaciones de aprendizaje profundo es tener tus tensores en diferentes tipos de datos.\n",
    "\n",
    "Si un tensor está en `torch.float64` y otro está en `torch.float32`, podrías tener algunos errores.\n",
    "\n",
    "Pero hay una solución.\n",
    "\n",
    "Puedes cambiar los tipos de datos de tensores usando [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) donde el parámetro `dtype` es el tipo de dato que te gustaría usar.\n",
    "\n",
    "Primero crearemos un tensor y verificaremos su tipo de dato (el predeterminado es `torch.float32`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor y verificar su tipo de dato\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearemos otro tensor igual que antes pero cambiaremos su tipo de dato a `torch.float16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor float16\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos hacer algo similar para hacer un tensor `torch.int8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor int8\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota:** Los diferentes tipos de datos pueden ser confusos al principio. Pero piénsalo así, entre menor el número (ej. 32, 16, 8), menos precisa una computadora almacena el valor. Y con una menor cantidad de almacenamiento, esto generalmente resulta en computación más rápida y un modelo general más pequeño. Las redes neuronales basadas en móviles a menudo operan con enteros de 8-bit, más pequeños y rápidos de ejecutar pero menos precisos que sus contrapartes float32. Para más sobre esto, leería sobre [precisión en computación](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
    "\n",
    "> **Ejercicio:** Hasta ahora hemos cubierto bastantes métodos de tensor pero hay muchos más en la [documentación de `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html), recomendaría pasar 10 minutos navegando y viendo cualquiera que te llame la atención. Haz clic en ellos y luego escríbelos en código tú mismo para ver qué pasa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redimensionando, apilando, exprimiendo y desexprimiendo\n",
    "\n",
    "A menudo querrás redimensionar o cambiar las dimensiones de tus tensores sin realmente cambiar los valores dentro de ellos.\n",
    "\n",
    "Para hacerlo, algunos métodos populares son:\n",
    "\n",
    "| Método | Descripción de una línea |\n",
    "| ----- | ----- |\n",
    "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Redimensiona `input` a `shape` (si es compatible), también se puede usar `torch.Tensor.reshape()`. |\n",
    "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Devuelve una vista del tensor original en una `shape` diferente pero comparte los mismos datos que el tensor original. |\n",
    "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatena una secuencia de `tensors` a lo largo de una nueva dimensión (`dim`), todos los `tensors` deben ser del mismo tamaño. |\n",
    "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Exprime `input` para remover todas las dimensiones con valor `1`. |\n",
    "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Devuelve `input` con una dimensión de valor `1` agregada en `dim`. |\n",
    "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Devuelve una *vista* del `input` original con sus dimensiones permutadas (reorganizadas) a `dims`. |\n",
    "\n",
    "¿Por qué hacer cualquiera de estos?\n",
    "\n",
    "Porque los modelos de aprendizaje profundo (redes neuronales) son todos sobre manipular tensores de alguna manera. Y por las reglas de multiplicación de matrices, si tienes desajustes de forma, tendrás errores. Estos métodos te ayudan a asegurarte de que los elementos correctos de tus tensores se estén mezclando con los elementos correctos de otros tensores.\n",
    "\n",
    "Probémoslos.\n",
    "\n",
    "Primero, crearemos un tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor\n",
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora agreguemos una dimensión extra con `torch.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una dimensión extra\n",
    "x_redimensionado = x.reshape(1, 7)\n",
    "x_redimensionado, x_redimensionado.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos cambiar la vista con `torch.view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar vista (mantiene los mismos datos que el original pero cambia la vista)\n",
    "# Ver más: https://stackoverflow.com/a/54507446/7900723\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda sin embargo, cambiar la vista de un tensor con `torch.view()` realmente solo crea una nueva vista del *mismo* tensor.\n",
    "\n",
    "Así que cambiar la vista cambia el tensor original también."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar z cambia x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisiéramos apilar nuestro nuevo tensor encima de sí mismo cinco veces, podríamos hacerlo con `torch.stack()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apilar tensores uno encima del otro\n",
    "x_apilado = torch.stack([x, x, x, x], dim=0) # prueba cambiar dim a dim=1 y ve qué pasa\n",
    "x_apilado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué tal remover todas las dimensiones únicas de un tensor?\n",
    "\n",
    "Para hacerlo puedes usar `torch.squeeze()` (recuerdo esto como *exprimir* el tensor para solo tener dimensiones mayores a 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tensor previo: {x_redimensionado}\")\n",
    "print(f\"Forma previa: {x_redimensionado.shape}\")\n",
    "\n",
    "# Remover dimensión extra de x_redimensionado\n",
    "x_exprimido = x_redimensionado.squeeze()\n",
    "print(f\"\\nNuevo tensor: {x_exprimido}\")\n",
    "print(f\"Nueva forma: {x_exprimido.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y para hacer lo contrario de `torch.squeeze()` puedes usar `torch.unsqueeze()` para agregar una dimensión de valor 1 en un índice específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tensor previo: {x_exprimido}\")\n",
    "print(f\"Forma previa: {x_exprimido.shape}\")\n",
    "\n",
    "## Agregar una dimensión extra con unsqueeze\n",
    "x_desexprimido = x_exprimido.unsqueeze(dim=0)\n",
    "print(f\"\\nNuevo tensor: {x_desexprimido}\")\n",
    "print(f\"Nueva forma: {x_desexprimido.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes reorganizar el orden de los valores de ejes con `torch.permute(input, dims)`, donde el `input` se convierte en una *vista* con nuevos `dims`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tensor con forma específica\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permutar el tensor original para reorganizar el orden de los ejes\n",
    "x_permutado = x_original.permute(2, 0, 1) # cambia eje 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Forma previa: {x_original.shape}\")\n",
    "print(f\"Nueva forma: {x_permutado.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Porque permutar devuelve una *vista* (comparte los mismos datos que el original), los valores en el tensor permutado serán los mismos que el tensor original y si cambias los valores en la vista, cambiará los valores del original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexación (seleccionando datos de tensores)\n",
    "\n",
    "A veces querrás seleccionar datos específicos de tensores (por ejemplo, solo la primera columna o segunda fila).\n",
    "\n",
    "Para hacerlo, puedes usar indexación.\n",
    "\n",
    "Si alguna vez has hecho indexación en listas de Python o arrays de NumPy, la indexación en PyTorch con tensores es muy similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexar valores va dimensión exterior -> dimensión interior (revisa los corchetes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexemos corchete por corchete\n",
    "print(f\"Primer corchete:\\n{x[0]}\") \n",
    "print(f\"Segundo corchete: {x[0][0]}\") \n",
    "print(f\"Tercer corchete: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes usar `:` para especificar \"todos los valores en esta dimensión\" y luego usar una coma (`,`) para agregar otra dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los valores de la dimensión 0 y el índice 0 de la dimensión 1\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los valores de las dimensiones 0 y 1 pero solo el índice 1 de la dimensión 2\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los valores de la dimensión 0 pero solo el valor del índice 1 de las dimensiones 1 y 2\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener índice 0 de las dimensiones 0 y 1 y todos los valores de la dimensión 2\n",
    "x[0, 0, :] # igual que x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La indexación puede ser bastante confusa al principio, especialmente con tensores más grandes (todavía tengo que probar indexación múltiples veces para hacerlo bien). Pero con un poco de práctica y siguiendo el lema del explorador de datos (***visualizar, visualizar, visualizar***), empezarás a entenderlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores de PyTorch y NumPy\n",
    "\n",
    "Dado que NumPy es una librería popular de computación numérica de Python, PyTorch tiene funcionalidad para interactuar con ella de manera agradable.\n",
    "\n",
    "Los dos métodos principales que querrás usar para NumPy a PyTorch (y de vuelta otra vez) son:\n",
    "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - array de NumPy -> tensor de PyTorch.\n",
    "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - tensor de PyTorch -> array de NumPy.\n",
    "\n",
    "Probémoslos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array de NumPy a tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota:** Por defecto, los arrays de NumPy se crean con el tipo de dato `float64` y si lo conviertes a un tensor de PyTorch, mantendrá el mismo tipo de dato (como arriba).\n",
    ">\n",
    "> Sin embargo, muchos cálculos de PyTorch por defecto usan `float32`.\n",
    ">\n",
    "> Así que si quieres convertir tu array de NumPy (float64) -> tensor de PyTorch (float64) -> tensor de PyTorch (float32), puedes usar `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
    "\n",
    "Porque reasignamos `tensor` arriba, si cambias el tensor, el array se mantiene igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el array, mantener el tensor\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y si quieres ir de tensor de PyTorch a array de NumPy, puedes llamar `tensor.numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor a array de NumPy\n",
    "tensor = torch.ones(7) # crear un tensor de unos con dtype=float32\n",
    "numpy_tensor = tensor.numpy() # será dtype=float32 a menos que se cambie\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la misma regla se aplica que arriba, si cambias el `tensor` original, el nuevo `numpy_tensor` se mantiene igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el tensor, mantener el array igual\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibilidad (tratando de sacar lo aleatorio de lo aleatorio)\n",
    "\n",
    "A medida que aprendes más sobre redes neuronales y aprendizaje automático, empezarás a descubrir cuánto juega un papel la aleatoriedad.\n",
    "\n",
    "Bueno, pseudoaleatoriedad eso es. Porque después de todo, como están diseñadas, una computadora es fundamentalmente determinista (cada paso es predecible) así que la aleatoriedad que crean son aleatoriedad simulada (aunque también hay debate sobre esto, pero como no soy científico en computación, te dejaré averiguar más por ti mismo).\n",
    "\n",
    "¿Cómo se relaciona esto con redes neuronales y aprendizaje profundo entonces?\n",
    "\n",
    "Hemos discutido que las redes neuronales comienzan con números aleatorios para describir patrones en datos (estos números son descripciones pobres) e intentan mejorar esos números aleatorios usando operaciones de tensor (y algunas otras cosas que no hemos discutido aún) para describir mejor los patrones en datos.\n",
    "\n",
    "En resumen:\n",
    "\n",
    "``comenzar con números aleatorios -> operaciones de tensor -> tratar de hacer mejor (una y otra y otra vez)``\n",
    "\n",
    "Aunque la aleatoriedad es buena y poderosa, a veces te gustaría que hubiera un poco menos aleatoriedad.\n",
    "\n",
    "¿Por qué?\n",
    "\n",
    "Para que puedas realizar experimentos repetibles.\n",
    "\n",
    "Por ejemplo, creas un algoritmo capaz de lograr rendimiento X.\n",
    "\n",
    "Y luego tu amigo lo prueba para verificar que no estás loco.\n",
    "\n",
    "¿Cómo podría hacer tal cosa?\n",
    "\n",
    "Ahí es donde entra la **reproducibilidad**.\n",
    "\n",
    "En otras palabras, ¿puedes obtener los mismos (o muy similares) resultados en tu computadora ejecutando el mismo código que yo obtengo en la mía?\n",
    "\n",
    "Veamos un ejemplo breve de reproducibilidad en PyTorch.\n",
    "\n",
    "Comenzaremos creando dos tensores aleatorios, dado que son aleatorios, esperarías que fueran diferentes ¿verdad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Crear dos tensores aleatorios\n",
    "tensor_aleatorio_A = torch.rand(3, 4)\n",
    "tensor_aleatorio_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{tensor_aleatorio_A}\\n\")\n",
    "print(f\"Tensor B:\\n{tensor_aleatorio_B}\\n\")\n",
    "print(f\"¿Tensor A es igual a Tensor B? (en cualquier lugar)\")\n",
    "tensor_aleatorio_A == tensor_aleatorio_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justo como podrías haber esperado, los tensores salen con valores diferentes.\n",
    "\n",
    "Pero ¿qué tal si quisieras crear dos tensores aleatorios con los *mismos* valores?\n",
    "\n",
    "Como en, los tensores todavía contendrían valores aleatorios pero serían del mismo sabor.\n",
    "\n",
    "Ahí es donde entra [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html), donde `seed` es un entero (como `42` pero podría ser cualquier cosa) que saboriza la aleatoriedad.\n",
    "\n",
    "Probémoslo creando algunos tensores aleatorios más *saborizados*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# # Establecer la semilla aleatoria\n",
    "SEMILLA_ALEATORIA=42 # prueba cambiar esto a diferentes valores y ve qué pasa a los números abajo\n",
    "torch.manual_seed(seed=SEMILLA_ALEATORIA) \n",
    "tensor_aleatorio_C = torch.rand(3, 4)\n",
    "\n",
    "# Hay que resetear la semilla cada vez que se llama un nuevo rand()\n",
    "# Sin esto, tensor_D sería diferente a tensor_C\n",
    "torch.random.manual_seed(seed=SEMILLA_ALEATORIA) # prueba comentar esta línea y ver qué pasa\n",
    "tensor_aleatorio_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{tensor_aleatorio_C}\\n\")\n",
    "print(f\"Tensor D:\\n{tensor_aleatorio_D}\\n\")\n",
    "print(f\"¿Tensor C es igual a Tensor D? (en cualquier lugar)\")\n",
    "tensor_aleatorio_C == tensor_aleatorio_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Genial!\n",
    "\n",
    "Parece que establecer la semilla funcionó.\n",
    "\n",
    "> **Recurso:** Lo que acabamos de cubrir solo rasca la superficie de reproducibilidad en PyTorch. Para más, sobre reproducibilidad en general y semillas aleatorias, revisaría:\n",
    "> * [La documentación de reproducibilidad de PyTorch](https://pytorch.org/docs/stable/notes/randomness.html) (un buen ejercicio sería leer esto por 10 minutos e incluso si no lo entiendes ahora, estar consciente de ello es importante).\n",
    "> * [La página de Wikipedia de semilla aleatoria](https://en.wikipedia.org/wiki/Random_seed) (esto dará un buen resumen de semillas aleatorias y pseudoaleatoriedad en general)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutando tensores en GPUs (y haciendo cálculos más rápidos)\n",
    "\n",
    "Los algoritmos de aprendizaje profundo requieren muchas operaciones numéricas.\n",
    "\n",
    "Y por defecto estas operaciones se hacen a menudo en una CPU (unidad de procesamiento de computadora).\n",
    "\n",
    "Sin embargo, hay otra pieza común de hardware llamada GPU (unidad de procesamiento gráfico), que es a menudo mucho más rápida realizando los tipos específicos de operaciones que las redes neuronales necesitan (multiplicaciones de matrices) que las CPUs.\n",
    "\n",
    "Tu computadora podría tener una.\n",
    "\n",
    "Si es así, deberías buscar usarla cuando puedas para entrenar redes neuronales porque las probabilidades son que acelere el tiempo de entrenamiento dramáticamente.\n",
    "\n",
    "Hay algunas maneras de primero obtener acceso a una GPU y segundo hacer que PyTorch use la GPU.\n",
    "\n",
    "> **Nota:** Cuando referencio \"GPU\" a través de este curso, estoy referenciando una [GPU Nvidia con CUDA habilitado](https://developer.nvidia.com/cuda-gpus) (CUDA es una plataforma de computación y API que ayuda a permitir que las GPUs se usen para computación de propósito general y no solo gráficos) a menos que se especifique de otra manera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obteniendo una GPU\n",
    "\n",
    "Ya podrías saber qué está pasando cuando digo GPU. Pero si no, hay algunas maneras de obtener acceso a una.\n",
    "\n",
    "| **Método** | **Dificultad para configurar** | **Pros** | **Contras** | **Cómo configurar** |\n",
    "| ----- | ----- | ----- | ----- | ----- |\n",
    "| Google Colab | Fácil | Gratis de usar, casi configuración cero requerida, puede compartir trabajo con otros tan fácil como un enlace | No guarda las salidas de tus datos, cómputo limitado, sujeto a timeouts | [Sigue la Guía de Google Colab](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
    "| Usar la tuya | Medio | Ejecutar todo localmente en tu propia máquina | Las GPUs no son gratis, requieren costo inicial | Sigue las [pautas de instalación de PyTorch](https://pytorch.org/get-started/locally/) |\n",
    "| Computación en la nube (AWS, GCP, Azure) | Medio-Difícil | Pequeño costo inicial, acceso a casi cómputo infinito | Puede volverse caro si se ejecuta continuamente, toma algo de tiempo configurar correctamente | Sigue las [pautas de instalación de PyTorch](https://pytorch.org/get-started/cloud-partners/) |\n",
    "\n",
    "Hay más opciones para usar GPUs pero las tres de arriba serán suficientes por ahora.\n",
    "\n",
    "Personalmente, uso una combinación de Google Colab y mi computadora personal para experimentos de pequeña escala (y crear este curso) y voy a recursos en la nube cuando necesito más poder de cómputo.\n",
    "\n",
    "> **Recurso:** Si estás buscando comprar una GPU propia pero no estás seguro de qué obtener, [Tim Dettmers tiene una excelente guía](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
    "\n",
    "Para verificar si tienes acceso a una GPU Nvidia, puedes ejecutar `!nvidia-smi` donde el `!` (también llamado bang) significa \"ejecutar esto en la línea de comando\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no tienes una GPU Nvidia accesible, lo de arriba dará como salida algo como:\n",
    "\n",
    "```\n",
    "NVIDIA-SMI ha fallado porque no pudo comunicarse con el controlador NVIDIA. Asegúrate de que el controlador NVIDIA más reciente esté instalado y ejecutándose.\n",
    "```\n",
    "\n",
    "En ese caso, regresa arriba y sigue los pasos de instalación.\n",
    "\n",
    "Si tienes una GPU, la línea de arriba dará como salida algo como:\n",
    "\n",
    "```\n",
    "Wed Jan 19 22:09:08 2022       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
    "|-------------------------------+----------------------+----------------------|\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------|\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hacer que PyTorch se ejecute en la GPU\n",
    "\n",
    "Una vez que tengas una GPU lista para acceder, el siguiente paso es hacer que PyTorch la use para almacenar datos (tensores) y computar en datos (realizar operaciones en tensores).\n",
    "\n",
    "Para hacerlo, puedes usar el paquete [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html).\n",
    "\n",
    "En lugar de hablar sobre ello, probémoslo.\n",
    "\n",
    "Puedes probar si PyTorch tiene acceso a una GPU usando [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar por GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo de arriba da como salida `True`, PyTorch puede ver y usar la GPU, si da como salida `False`, no puede ver la GPU y en ese caso, tendrás que regresar por los pasos de instalación.\n",
    "\n",
    "Ahora, digamos que quisieras configurar tu código para que se ejecute en CPU *o* la GPU si estuviera disponible.\n",
    "\n",
    "De esa manera, si tú o alguien decide ejecutar tu código, funcionará independientemente del dispositivo de cómputo que estén usando.\n",
    "\n",
    "Creemos una variable `device` para almacenar qué tipo de dispositivo está disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer tipo de dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo de arriba da como salida `\"cuda\"` significa que podemos establecer todo nuestro código de PyTorch para usar el dispositivo CUDA disponible (una GPU) y si da como salida `\"cpu\"`, nuestro código de PyTorch se quedará con la CPU.\n",
    "\n",
    "> **Nota:** En PyTorch, es mejor práctica escribir [**código agnóstico de dispositivo**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). Esto significa código que se ejecutará en CPU (siempre disponible) o GPU (si está disponible).\n",
    "\n",
    "Si quieres hacer cómputo más rápido puedes usar una GPU pero si quieres hacer cómputo *mucho* más rápido, puedes usar múltiples GPUs.\n",
    "\n",
    "Puedes contar el número de GPUs a las que PyTorch tiene acceso usando [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar número de dispositivos\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conocer el número de GPUs a las que PyTorch tiene acceso es útil en caso de que quisieras ejecutar un proceso específico en una GPU y otro proceso en otra (PyTorch también tiene características para dejarte ejecutar un proceso a través de *todas* las GPUs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Hacer que PyTorch se ejecute en Apple Silicon\n",
    "\n",
    "Para ejecutar PyTorch en las GPUs M1/M2/M3 de Apple puedes usar el módulo [`torch.backends.mps`](https://pytorch.org/docs/stable/notes/mps.html).\n",
    "\n",
    "Asegúrate de que las versiones de macOS y PyTorch estén actualizadas.\n",
    "\n",
    "Puedes probar si PyTorch tiene acceso a una GPU usando `torch.backends.mps.is_available()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar por GPU de Apple Silicon\n",
    "import torch\n",
    "torch.backends.mps.is_available() # Nota que esto imprimirá false si no estás ejecutando en una Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer tipo de dispositivo\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como antes, si lo de arriba da como salida `\"mps\"` significa que podemos establecer todo nuestro código de PyTorch para usar la GPU Apple Silicon disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # Usar GPU NVIDIA (si está disponible)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Usar GPU Apple Silicon (si está disponible)\n",
    "else:\n",
    "    device = \"cpu\" # Por defecto a CPU si no hay GPU disponible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Poniendo tensores (y modelos) en la GPU\n",
    "\n",
    "Puedes poner tensores (y modelos, lo veremos después) en un dispositivo específico llamando [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) en ellos. Donde `device` es el dispositivo objetivo al que te gustaría que el tensor (o modelo) vaya.\n",
    "\n",
    "¿Por qué hacer esto?\n",
    "\n",
    "Las GPUs ofrecen computación numérica mucho más rápida que las CPUs y si una GPU no está disponible, por nuestro **código agnóstico de dispositivo** (ver arriba), se ejecutará en la CPU.\n",
    "\n",
    "> **Nota:** Poner un tensor en GPU usando `to(device)` (ej. `algun_tensor.to(device)`) devuelve una copia de ese tensor, ej. el mismo tensor estará en CPU y GPU. Para sobrescribir tensores, reasígnalos:\n",
    ">\n",
    "> `algun_tensor = algun_tensor.to(device)`\n",
    "\n",
    "Probemos crear un tensor y ponerlo en la GPU (si está disponible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tensor (por defecto en CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor no en GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Mover tensor a GPU (si está disponible)\n",
    "tensor_en_gpu = tensor.to(device)\n",
    "tensor_en_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tienes una GPU disponible, el código de arriba dará como salida algo como:\n",
    "\n",
    "```\n",
    "tensor([1, 2, 3]) cpu\n",
    "tensor([1, 2, 3], device='cuda:0')\n",
    "```\n",
    "\n",
    "Nota que el segundo tensor tiene `device='cuda:0'`, esto significa que está almacenado en la GPU 0 disponible (las GPUs están indexadas en 0, si dos GPUs estuvieran disponibles, serían `'cuda:0'` y `'cuda:1'` respectivamente, hasta `'cuda:n'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Moviendo tensores de vuelta a la CPU\n",
    "\n",
    "¿Qué tal si quisiéramos mover el tensor de vuelta a CPU?\n",
    "\n",
    "Por ejemplo, querrás hacer esto si quieres interactuar con tus tensores con NumPy (NumPy no aprovecha la GPU).\n",
    "\n",
    "Probemos usar el método [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) en nuestro `tensor_en_gpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si el tensor está en GPU, no se puede transformar a NumPy (esto dará error)\n",
    "tensor_en_gpu.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En su lugar, para obtener un tensor de vuelta a CPU y usable con NumPy podemos usar [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html).\n",
    "\n",
    "Esto copia el tensor a memoria de CPU para que sea usable con CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En su lugar, copiar el tensor de vuelta a cpu\n",
    "tensor_de_vuelta_en_cpu = tensor_en_gpu.cpu().numpy()\n",
    "tensor_de_vuelta_en_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo de arriba devuelve una copia del tensor de GPU en memoria de CPU así que el tensor original sigue en GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_en_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "Todos los ejercicios se enfocan en practicar el código de arriba.\n",
    "\n",
    "Deberías poder completarlos referenciando cada sección o siguiendo el/los recurso(s) enlazados.\n",
    "\n",
    "**Recursos:**\n",
    "\n",
    "* [Notebook plantilla de ejercicios para 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb).\n",
    "* [Notebook de soluciones ejemplo para 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/00_pytorch_fundamentals_exercise_solutions.ipynb) (prueba los ejercicios *antes* de ver esto).\n",
    "\n",
    "1. Lectura de documentación - Una gran parte del aprendizaje profundo (y aprender a programar en general) es familiarizarse con la documentación de cierto framework que estés usando. Estaremos usando mucho la documentación de PyTorch a través del resto de este curso. Así que recomendaría pasar 10 minutos leyendo lo siguiente (está bien si no entiendes algunas cosas por ahora, el enfoque no es aún comprensión completa, es consciencia). Ve la documentación en [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor) y para [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
    "2. Crear un tensor aleatorio con forma `(7, 7)`.\n",
    "3. Realizar una multiplicación de matrices en el tensor del 2 con otro tensor aleatorio con forma `(1, 7)` (pista: podrías tener que transponer el segundo tensor).\n",
    "4. Establecer la semilla aleatoria a `0` y hacer los ejercicios 2 y 3 otra vez.\n",
    "5. Hablando de semillas aleatorias, vimos cómo establecerla con `torch.manual_seed()` pero ¿hay un equivalente de GPU? (pista: necesitarás buscar en la documentación para `torch.cuda` para este). Si lo hay, establece la semilla aleatoria de GPU a `1234`.\n",
    "6. Crear dos tensores aleatorios de forma `(2, 3)` y enviarlos ambos a la GPU (necesitarás acceso a una GPU para esto). Establece `torch.manual_seed(1234)` cuando crees los tensores (esto no tiene que ser la semilla aleatoria de GPU).\n",
    "7. Realizar una multiplicación de matrices en los tensores que creaste en 6 (otra vez, podrías tener que ajustar las formas de uno de los tensores).\n",
    "8. Encontrar los valores máximos y mínimos de la salida del 7.\n",
    "9. Encontrar los valores de índice máximos y mínimos de la salida del 7.\n",
    "10. Hacer un tensor aleatorio con forma `(1, 1, 1, 10)` y luego crear un nuevo tensor con todas las dimensiones `1` removidas para quedar con un tensor de forma `(10)`. Establece la semilla a `7` cuando lo crees e imprime el primer tensor y su forma así como el segundo tensor y su forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Currículo extra\n",
    "\n",
    "* Pasar 1 hora pasando por el [tutorial de básicos de PyTorch](https://pytorch.org/tutorials/beginner/basics/intro.html) (recomendaría las secciones [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) y [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)).\n",
    "* Para aprender más sobre cómo un tensor puede representar datos, ve este video: [¿Qué es un tensor?](https://youtu.be/f5liqUk0ZTw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
